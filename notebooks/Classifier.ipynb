{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impaired-project",
   "metadata": {
    "papermill": {
     "duration": 0.020675,
     "end_time": "2021-02-21T10:16:49.775553",
     "exception": false,
     "start_time": "2021-02-21T10:16:49.754878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Telegram Mining (Notebook Autor-Klassifizierung)\n",
    "\n",
    "**Master-Thesis: Social Media & Text Mining am Beispiel von Telegram**\n",
    "\n",
    "Informatik Master\n",
    "\n",
    "Maximilian Bundscherer\n",
    "\n",
    "**Hinweis**: Die Abschnitte ``Arbeitungsumgebung initalisieren`` und ``Chats laden und aufbereiten`` werden im Notebook ``Telegram.iypnb`` bereits ausführlich beschrieben und werden daher hier übersprungen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-japanese",
   "metadata": {},
   "source": [
    "## Arbeitumgsbebung initalisieren\n",
    "\n",
    "Siehe Beschreibung im Notebook ``Telegram.ipynb``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-wisdom",
   "metadata": {
    "papermill": {
     "duration": 0.814002,
     "end_time": "2021-02-21T10:16:50.657549",
     "exception": false,
     "start_time": "2021-02-21T10:16:49.843547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import default libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import demjson\n",
    "import requests\n",
    "import networkx as nx\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from lxml.html import fromstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide DeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-guest",
   "metadata": {
    "papermill": {
     "duration": 3.081832,
     "end_time": "2021-02-21T10:16:53.759405",
     "exception": false,
     "start_time": "2021-02-21T10:16:50.677573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import demoji\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictGloStopwatches = dict()\n",
    "\n",
    "# Start timer (for reporting)\n",
    "def gloStartStopwatch(key):\n",
    "    print(\"[Stopwatch started >>\" + str(key) + \"<<]\")\n",
    "    dictGloStopwatches[key] = time.time()\n",
    "\n",
    "# Stop timer (for reporting)\n",
    "def gloStopStopwatch(key):\n",
    "    endTime     = time.time()\n",
    "    startTime   = dictGloStopwatches[key]\n",
    "    print(\"[Stopwatch stopped >>\" + str(key) + \"<< (\" + '{:5.3f}s'.format(endTime-startTime) + \")]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-hospital",
   "metadata": {
    "papermill": {
     "duration": 0.49131,
     "end_time": "2021-02-21T10:16:54.274068",
     "exception": false,
     "start_time": "2021-02-21T10:16:53.782758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns (pandas hides columns by default)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "font = {'size'   : 13}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-wedding",
   "metadata": {
    "papermill": {
     "duration": 0.028985,
     "end_time": "2021-02-21T10:16:54.536381",
     "exception": false,
     "start_time": "2021-02-21T10:16:54.507396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_var                 = \"./\"\n",
    "dir_var_output          = dir_var + \"output/\"\n",
    "dir_var_pandas_cache    = dir_var + \"cache/pandas/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-radar",
   "metadata": {
    "papermill": {
     "duration": 0.030344,
     "end_time": "2021-02-21T10:16:54.643395",
     "exception": false,
     "start_time": "2021-02-21T10:16:54.613051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gloReplaceGermanChars(inputText):\n",
    "\n",
    "    inputText = inputText.replace(\"ö\", \"oe\")\n",
    "    inputText = inputText.replace(\"ü\", \"ue\")\n",
    "    inputText = inputText.replace(\"ä\", \"ae\")\n",
    "\n",
    "    inputText = inputText.replace(\"Ö\", \"Oe\")\n",
    "    inputText = inputText.replace(\"Ü\", \"Ue\")\n",
    "    inputText = inputText.replace(\"Ä\", \"Ae\")\n",
    "\n",
    "    inputText = inputText.replace(\"ß\", \"ss\")\n",
    "    \n",
    "    return inputText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-market",
   "metadata": {
    "papermill": {
     "duration": 0.029065,
     "end_time": "2021-02-21T10:16:54.696673",
     "exception": false,
     "start_time": "2021-02-21T10:16:54.667608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rm unsafe chars\n",
    "def gloConvertToSafeString(text):\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = gloReplaceGermanChars(text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Generate unique chat name\n",
    "def gloConvertToSafeChatName(chatName):\n",
    "    chatName = gloConvertToSafeString(chatName)\n",
    "    return chatName[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-delivery",
   "metadata": {
    "papermill": {
     "duration": 0.030425,
     "end_time": "2021-02-21T10:16:54.750369",
     "exception": false,
     "start_time": "2021-02-21T10:16:54.719944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gloGetStopWordsList(filterList):\n",
    "\n",
    "    stopwWorldsList = []\n",
    "\n",
    "    deWordsList = nltk.corpus.stopwords.words('german')\n",
    "\n",
    "    enWordsList = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    aStopwords = []\n",
    "    with open(dir_var + \"additionalStopwords.txt\") as file:\n",
    "        for line in file: \n",
    "            line = line.strip()\n",
    "            if(line != \"\"):\n",
    "                aStopwords.append(line)\n",
    "\n",
    "    for s in filterList:\n",
    "        s = gloReplaceGermanChars(s)\n",
    "        stopwWorldsList.append(s)\n",
    "\n",
    "    for s in deWordsList:\n",
    "        s = gloReplaceGermanChars(s)\n",
    "        stopwWorldsList.append(s)\n",
    "\n",
    "    for s in enWordsList:\n",
    "        stopwWorldsList.append(s)\n",
    "\n",
    "    for s in aStopwords:\n",
    "        s = gloReplaceGermanChars(s)\n",
    "        stopwWorldsList.append(s)\n",
    "\n",
    "    return stopwWorldsList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-latest",
   "metadata": {
    "papermill": {
     "duration": 0.08062,
     "end_time": "2021-02-21T10:16:54.378509",
     "exception": false,
     "start_time": "2021-02-21T10:16:54.297889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Chats laden und aufbereiten\n",
    "\n",
    "Siehe Beschreibung im Notebook ``Telegram.ipynb``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-renaissance",
   "metadata": {
    "papermill": {
     "duration": 0.023122,
     "end_time": "2021-02-21T10:17:32.535280",
     "exception": false,
     "start_time": "2021-02-21T10:17:32.512158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Klassifizierung nach Autoren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-rehabilitation",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-penny",
   "metadata": {
    "papermill": {
     "duration": 0.029242,
     "end_time": "2021-02-21T10:16:49.824563",
     "exception": false,
     "start_time": "2021-02-21T10:16:49.795321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "C_USE_CACHE_FILE = \"final-run-24-03.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-romania",
   "metadata": {},
   "source": [
    "#### Von Cache Laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-footage",
   "metadata": {
    "papermill": {
     "duration": 20.803001,
     "end_time": "2021-02-21T10:17:15.577412",
     "exception": false,
     "start_time": "2021-02-21T10:16:54.774411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gloStartStopwatch(\"Cache einlesen\")\n",
    "dfAllDataMessages = pd.read_pickle(dir_var_pandas_cache + C_USE_CACHE_FILE)\n",
    "gloStopStopwatch(\"Cache einlesen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-stanford",
   "metadata": {},
   "source": [
    "#### Filtern und anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-victorian",
   "metadata": {
    "papermill": {
     "duration": 16.834003,
     "end_time": "2021-02-21T10:17:32.434638",
     "exception": false,
     "start_time": "2021-02-21T10:17:15.600635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfAllDataMessages= dfAllDataMessages[dfAllDataMessages['ftFilePath'].isin(\n",
    "    [\n",
    "        \"DS-05-01-2021/ChatExport_2021-01-05-hildmann\",\n",
    "        \"DS-05-01-2021/ChatExport_2021-01-05-janich\",\n",
    "        \"DS-05-01-2021/ChatExport_2021-01-05-xavier\",\n",
    "        \"DS-05-01-2021/ChatExport_2021-01-05-evaherman\"\n",
    "    ]\n",
    ")]\n",
    "\n",
    "dfAllDataMessages = dfAllDataMessages[dfAllDataMessages.ftQrIsValidText == True]\n",
    "dfAllDataMessages = dfAllDataMessages[dfAllDataMessages.ftTdCleanText != \"\"]\n",
    "dfAllDataMessages = dfAllDataMessages[dfAllDataMessages.ftTdTextLength > 5]\n",
    "#dfAllDataMessages = dfAllDataMessages[dfAllDataMessages.ftChatType == \"public_channel\"]\n",
    "\n",
    "dfAllDataMessages[\"from\"] = dfAllDataMessages[\"from\"].apply(gloConvertToSafeChatName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAllDataMessages.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-cancer",
   "metadata": {},
   "source": [
    "### Daten aufbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-lingerie",
   "metadata": {},
   "source": [
    "#### Classifier Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-local",
   "metadata": {
    "papermill": {
     "duration": 0.040707,
     "end_time": "2021-02-21T10:17:32.717399",
     "exception": false,
     "start_time": "2021-02-21T10:17:32.676692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targetDf = dfAllDataMessages\n",
    "\n",
    "targetDf['clFrom']    = targetDf['from']\n",
    "targetDf['clFromId']  = targetDf['from'].factorize()[0]\n",
    "targetDf['clText']    = targetDf['ftTdCleanText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDf['clFrom'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDf['clFromId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDf['clText'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-mount",
   "metadata": {},
   "source": [
    "#### Dict From Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-cliff",
   "metadata": {
    "papermill": {
     "duration": 0.128934,
     "end_time": "2021-02-21T10:17:32.869944",
     "exception": false,
     "start_time": "2021-02-21T10:17:32.741010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfFromId            = targetDf[['clFrom', 'clFromId']].drop_duplicates().sort_values('clFromId')\n",
    "\n",
    "dictFrom_to_id= dict(dfFromId.values)\n",
    "dictId_to_from      = dict(dfFromId[['clFromId', 'clFrom']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-sense",
   "metadata": {
    "papermill": {
     "duration": 0.031271,
     "end_time": "2021-02-21T10:17:32.924721",
     "exception": false,
     "start_time": "2021-02-21T10:17:32.893450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictId_to_from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-china",
   "metadata": {},
   "source": [
    "#### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-bloom",
   "metadata": {
    "papermill": {
     "duration": 0.049364,
     "end_time": "2021-02-21T10:17:33.350634",
     "exception": false,
     "start_time": "2021-02-21T10:17:33.301270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(targetDf['clText'], targetDf['clFrom'], random_state = 42, test_size=0.20)\n",
    "\n",
    "print(\"Train size:\\t\" + str(len(X_train.index)))\n",
    "print(\"Test size:\\t\" + str(len(X_test.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-banking",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = test.fit_transform([\"Word1 Word2 Word3 Word4 Word1 Word2 Word1\"])\n",
    "d1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = test.transform([\"Word1 Wrong Word3 Wrong Word1\"])\n",
    "d2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-fields",
   "metadata": {},
   "source": [
    "#### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fit_transform(d1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.transform(d2).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-archive",
   "metadata": {},
   "source": [
    "### Tranieren und Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-incident",
   "metadata": {
    "papermill": {
     "duration": 4.134944,
     "end_time": "2021-02-21T10:17:37.510860",
     "exception": false,
     "start_time": "2021-02-21T10:17:33.375916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gloStartStopwatch(\"Transform messages\")\n",
    "\n",
    "count_vect          = CountVectorizer()\n",
    "tfidf_transformer   = TfidfTransformer()\n",
    "\n",
    "# Transform and fit train\n",
    "X_train_counts      = count_vect.fit_transform(X_train)\n",
    "X_train_tfidf       = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# Transform test\n",
    "X_test_counts       = count_vect.transform(X_test)\n",
    "X_test_tfidf        = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "gloStopStopwatch(\"Transform messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-original",
   "metadata": {
    "papermill": {
     "duration": 0.035824,
     "end_time": "2021-02-21T10:17:37.574564",
     "exception": false,
     "start_time": "2021-02-21T10:17:37.538740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainAndEvalModel(model, outputFilename):\n",
    "\n",
    "    gloStartStopwatch(\"- Train now model \" + str(model))\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    gloStopStopwatch(\"- Train now model \" + str(model))\n",
    "\n",
    "    searchStrings = [\"Folge Attila Hildmann\", \"Liebe Eva\", \"Premium Kanal\"]\n",
    "\n",
    "    for sS in searchStrings:\n",
    "\n",
    "        sS = str(sS)\n",
    "        print()\n",
    "        print(\"Who has written '\" + sS + \"'?\")\n",
    "        t = tfidf_transformer.transform(count_vect.transform([sS]))\n",
    "        r = model.predict(t)\n",
    "        print(str(r))\n",
    "\n",
    "    y_pred_train        = model.predict(X_train_tfidf)\n",
    "    y_pred_test         = model.predict(X_test_tfidf)\n",
    "\n",
    "    print()\n",
    "    print(\"Train Score:\\t\"  + str(accuracy_score(y_true=y_train, y_pred=y_pred_train)))\n",
    "    print(\"Test Score:\\t\"   + str(accuracy_score(y_true=y_test, y_pred=y_pred_test)))\n",
    "\n",
    "    print()\n",
    "    print(\"Confusion Matrix on test:\")   \n",
    "    \n",
    "    \n",
    "    \n",
    "    conf_mat = confusion_matrix(y_true = y_test, y_pred = y_pred_test)\n",
    "    fig, ax  = plt.subplots(figsize=(9,9))\n",
    "\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "                xticklabels=dfFromId.clFrom.values, yticklabels=dfFromId.clFrom.values)\n",
    "                \n",
    "    \n",
    "    \n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "\n",
    "    if(outputFilename != \"\"):\n",
    "        plt.savefig(dir_var_output + outputFilename)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-medication",
   "metadata": {},
   "source": [
    "#### Evaluation SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-annotation",
   "metadata": {
    "papermill": {
     "duration": 2.954488,
     "end_time": "2021-02-21T10:17:40.555086",
     "exception": false,
     "start_time": "2021-02-21T10:17:37.600598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(LinearSVC(), \"class-linearsvc.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-rocket",
   "metadata": {},
   "source": [
    "#### Evaluation Multinomialnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-jewelry",
   "metadata": {
    "papermill": {
     "duration": 0.900191,
     "end_time": "2021-02-21T10:17:41.489493",
     "exception": false,
     "start_time": "2021-02-21T10:17:40.589302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(MultinomialNB(), \"class-multinomialnb.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-amsterdam",
   "metadata": {},
   "source": [
    "#### Evaluation LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-narrow",
   "metadata": {
    "papermill": {
     "duration": 11.798661,
     "end_time": "2021-02-21T10:17:53.329583",
     "exception": false,
     "start_time": "2021-02-21T10:17:41.530922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(LogisticRegression(), \"class-logisticregression.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-speed",
   "metadata": {},
   "source": [
    "#### Evaluation MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-florist",
   "metadata": {
    "papermill": {
     "duration": 52723.191629,
     "end_time": "2021-02-22T00:56:36.572164",
     "exception": false,
     "start_time": "2021-02-21T10:17:53.380535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(MLPClassifier(), \"class-mlp.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-spread",
   "metadata": {},
   "source": [
    "#### Evaluation DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-valentine",
   "metadata": {
    "papermill": {
     "duration": 103.791273,
     "end_time": "2021-02-22T00:58:20.419836",
     "exception": false,
     "start_time": "2021-02-22T00:56:36.628563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(DecisionTreeClassifier(), \"class-decisiontree.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-standard",
   "metadata": {},
   "source": [
    "#### Evaluation RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-effectiveness",
   "metadata": {
    "papermill": {
     "duration": 1684.996386,
     "end_time": "2021-02-22T01:26:25.480457",
     "exception": false,
     "start_time": "2021-02-22T00:58:20.484071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(RandomForestClassifier(), \"class-randomforest.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-touch",
   "metadata": {},
   "source": [
    "#### Evaluation DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-peace",
   "metadata": {
    "papermill": {
     "duration": 0.662286,
     "end_time": "2021-02-22T01:26:26.214113",
     "exception": false,
     "start_time": "2021-02-22T01:26:25.551827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainAndEvalModel(DummyClassifier(strategy=\"uniform\"), \"class-dummy.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-regression",
   "metadata": {
    "papermill": {
     "duration": 0.079273,
     "end_time": "2021-02-22T01:26:26.373392",
     "exception": false,
     "start_time": "2021-02-22T01:26:26.294119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Mehr lesen / Inspirationen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-board",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "- https://towardsai.net/p/data-mining/text-mining-in-python-steps-and-examples-78b3f8fd913b\n",
    "- https://towardsdatascience.com/text-mining-for-dummies-text-classification-with-python-98e47c3a9deb\n",
    "- https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n",
    "- https://realpython.com/python-keras-text-classification/\n",
    "- https://www.tidytextmining.com/ngrams.html\n",
    "- http://seaborn.pydata.org/tutorial/categorical.html?highlight=bar%20plot\n",
    "- https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166\n",
    "- https://www.kirenz.com/post/2019-08-13-network_analysis/\n",
    "- https://tgstat.com\n",
    "- https://huggingface.co/bert-base-german-cased\n",
    "- https://github.com/sekhansen/text-mining-tutorial/tree/master\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "- https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "- https://github.com/sekhansen/text-mining-tutorial/blob/master/tutorial_notebook.ipynb\n",
    "- https://textmining.wp.hs-hannover.de/Preprocessing.html\n",
    "- https://likegeeks.com/nlp-tutorial-using-python-nltk/\n",
    "- https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk\n",
    "- https://data-flair.training/blogs/nltk-python-tutorial/\n",
    "- https://github.com/expectocode/telegram-analysis\n",
    "- https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 54578.915615,
   "end_time": "2021-02-22T01:26:27.561517",
   "environment_variables": {},
   "exception": null,
   "input_path": "work/notebooks/Classifier.ipynb",
   "output_path": "work/notebooks/Classifier-out.ipynb",
   "parameters": {},
   "start_time": "2021-02-21T10:16:48.645902",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
