{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set flag to true, if you work in visual studio code (connected to custom docker)\n",
    "Set flag to false, if you work in browser (jupyter notebook ui from custom docker)\n",
    "\"\"\"\n",
    "FLAG_LOCAL              = False\n",
    "\"\"\"\n",
    "Set flag to true, if you want to work an a spot check (quick run)\n",
    "\"\"\"\n",
    "FlAG_WORK_ON_SPOT_CHECK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import default libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import url libs\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "\n",
    "# Set graph widget (used by jupyter notebook)\n",
    "#%matplotlib notebook   #interactive graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.8/site-packages (1.4.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.8/site-packages (from pydot) (2.4.7)\r\n"
     ]
    }
   ],
   "source": [
    "# Install and import Graph Lib\n",
    "import networkx as nx\n",
    "! pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demjson in /opt/conda/lib/python3.8/site-packages (2.2.4)\r\n"
     ]
    }
   ],
   "source": [
    "# Install and import  JSON Lib\n",
    "! pip install demjson\n",
    "import demjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.54.1)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.0.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install and import Natural Language Toolkit\n",
    "! pip install nltk\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.8/site-packages (1.8.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from wordcloud) (8.0.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from wordcloud) (3.3.3)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from wordcloud) (1.19.4)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install and import WordCloud\n",
    "! pip install wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns (pandas hides columns by default)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Workdir -\n",
      "total 2964\n",
      "drwxrwxr-x 5 jovyan  1000    4096 Jan  1 16:22 .\n",
      "drwxrwxr-x 6 jovyan  1000    4096 Jan  1 10:38 ..\n",
      "drwxrwxr-x 4 jovyan  1000    4096 Dec 20 10:21 data\n",
      "-rw-rw-r-- 1 jovyan  1000    5295 Dec 20 10:51 inputFiles.csv\n",
      "drwxr-xr-x 2 jovyan users    4096 Dec 20 10:26 .ipynb_checkpoints\n",
      "drwxrwxr-x 2 jovyan  1000    4096 Jan  1 16:14 output\n",
      "-rwxrwxr-x 1 jovyan  1000 3005911 Jan  1 16:22 Telegram.ipynb\n",
      "\n",
      "- Outputdir -\n",
      "total 3196\n",
      "drwxrwxr-x 2 jovyan 1000   4096 Jan  1 16:14 .\n",
      "drwxrwxr-x 5 jovyan 1000   4096 Jan  1 16:22 ..\n",
      "-rw-rw-r-- 1 jovyan 1000      0 Dec 21 14:19 .gitkeep\n",
      "-rw-rw-r-- 1 jovyan 1000  62484 Jan  1 16:19 meta-overview.png\n",
      "-rw-rw-r-- 1 jovyan 1000  10889 Jan  1 16:19 meta-text-length-hist.png\n",
      "-rw-rw-r-- 1 jovyan 1000 525852 Jan  1 16:20 social-graph.png\n",
      "-rw-rw-r-- 1 jovyan 1000  36090 Jan  1 16:19 social-test-graph.png\n",
      "-rw-rw-r-- 1 jovyan 1000 547417 Jan  1 16:21 wordcloud-global.png\n",
      "-rw-rw-r-- 1 jovyan 1000 522478 Jan  1 16:20 wordcloud-pc-evaHerman.png\n",
      "-rw-rw-r-- 1 jovyan 1000 484726 Jan  1 16:20 wordcloud-pc-hildmann.png\n",
      "-rw-rw-r-- 1 jovyan 1000 534165 Jan  1 16:20 wordcloud-pc-janich.png\n",
      "-rw-rw-r-- 1 jovyan 1000 523648 Jan  1 16:20 wordcloud-pc-xavier.png\n"
     ]
    }
   ],
   "source": [
    "# Set env vars\n",
    "if(FLAG_LOCAL == True):\n",
    "    dir_var = \"./work/notebooks/\"\n",
    "else:\n",
    "    dir_var = \"./\"\n",
    "\n",
    "dir_var_output = dir_var + \"output/\"\n",
    "\n",
    "# Debug output\n",
    "! echo \"- Workdir -\"\n",
    "! ls -al $dir_var\n",
    "\n",
    "! echo\n",
    "! echo \"- Outputdir -\"\n",
    "! ls -al $dir_var_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check if text is json formatted\n",
    "\n",
    "param   text        InputText\n",
    "param   singleMode  Boolean (set to true, if text is part of a message)\n",
    "\"\"\"\n",
    "def gloCheckIsTextJsonFormatted(text, singleMode):\n",
    "    textString = str(text)\n",
    "    if      (singleMode == False and textString.startswith(\"[\") == True and textString.endswith(\"]\") == True):\n",
    "        return True\n",
    "    elif    (singleMode == True and textString.startswith(\"{\") == True and textString.endswith(\"}\") == True):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictGloStopwatches = dict()\n",
    "\n",
    "# Start timer (for reporting)\n",
    "def gloStartStopwatch(key):\n",
    "    print(\"[Stopwatch started >>\" + str(key) + \"<<]\")\n",
    "    dictGloStopwatches[key] = time.time()\n",
    "\n",
    "# Stop timer (for reporting)\n",
    "def gloStopStopwatch(key):\n",
    "    endTime     = time.time()\n",
    "    startTime   = dictGloStopwatches[key]\n",
    "    print(\"[Stopwatch stopped >>\" + str(key) + \"<< (\" + '{:5.3f}s'.format(endTime-startTime) + \")]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique chat name\n",
    "def gloConvertToSafeChatName(chatName):\n",
    "    chatName = chatName.encode('ascii', 'ignore')\n",
    "    chatName = chatName.decode('ascii')\n",
    "    return chatName[:30]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process input jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read jobs from file\n",
    "dfInputFiles = pd.read_csv(dir_var + \"inputFiles.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See description above (generate spot check)\n",
    "if(FlAG_WORK_ON_SPOT_CHECK == True):\n",
    "    dfFilter = pd.DataFrame()\n",
    "\n",
    "    dfFilter = dfFilter.append(dfInputFiles[dfInputFiles.inputName.str.contains(\"Xavier Naidoo\")])\n",
    "    dfFilter = dfFilter.append(dfInputFiles[dfInputFiles.inputName.str.contains(\"Oliver Janich\")])\n",
    "    dfFilter = dfFilter.append(dfInputFiles[dfInputFiles.inputName.str.contains(\"Eva Herman\")])\n",
    "    dfFilter = dfFilter.append(dfInputFiles[dfInputFiles.inputName.str.contains(\"ATTILA HILDMANN\")])\n",
    "\n",
    "    dfInputFiles = dfFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview input jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputName</th>\n",
       "      <th>inputPath</th>\n",
       "      <th>inputType</th>\n",
       "      <th>inputId</th>\n",
       "      <th>inputDesc</th>\n",
       "      <th>inputDownloadType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FREIHEITS-CHAT</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-28-freiheitsChat</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9717909816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oliver Janich oeffentlich</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-25-janich</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9808932799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATTILA HILDMANN OFFICIAL</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-25-hildmann</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10034163583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerechtigkeit fuer das Vaterland</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-26-gerechtigk...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10069007089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corona Virus Informationen</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-26-cvirusinfo</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9917074801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Liberte</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-26-liberte</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10068807626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Golden Age Network</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-26-goldenage</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9862302472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weltfrieden 2020</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-26-weltfriede...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9850980068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verschwoerungen</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-26-verschwoer...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9942502804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Digital Research Army</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-27-digitalRes...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9846664545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StefanRaven</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-27-stefanraven</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9820850677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Eva Herman Offiziell</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-27-evaherman</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9915108907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Xavier Naidoo (inoffiziell)</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-25-xavier</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9874390332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Digitaler Chronist</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-29-digitalerC...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10068312319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Das Prinz Telegramm</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-29-prinzTelegram</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9742969264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Strahlenkranz V....Merci Danke</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-29-strahlenkranz</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10050449614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wissensbewahrung Absicherung/Videokanal, Kultu...</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-absicherun...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9779767132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Holistische Gesundheit, Heilung und Aufklaerung</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-holistisch...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9758769198</td>\n",
       "      <td>not unique</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Metropol Chronicles</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-metropolChron</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9919682714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kulturstudio</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-kulturstudio</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10064728094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Medizinjournalist Rainer Taufertshoefer (oeffe...</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-rainerMedizin</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9804874080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Die Deutsche Loesung - Aufklaerung</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-deutscheAu...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9927244279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Die deutsche Loesung - Gruppe</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-09-30-deutscheLsg</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9982253319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>n8waechter.net</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-01-nachtwaechter</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9744633492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Deutsche Patrioten</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-01-deutschePatri</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9785040372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Patrioten im Widerstand</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-01-patriotenW...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9913028741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FREIHEITSCHAT - BLITZ</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-01-freiheitsC...</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9943834900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Antiilluminaten TV</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-02-antiillumi...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10060003597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DieWahrheitundnurdieWahrheit</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-02-chatDieWah...</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9969119455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ExpressZeitung</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-03-expressZei...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9857073102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Unzensiert</td>\n",
       "      <td>DS-08-10-2020/ChatExport_2020-10-04-unzensiert</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9725746662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Aufwachen</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-11-aufwachen</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9683270591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gesundheitsecke</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-11-gesundheit...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9706227251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wissen ist Weisheit</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-12-wissenWeis...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9691754437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>QAnons Channel</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-12-qAnonsGermany</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9804534747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Qanon Austria</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-13-qanonAustria</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9962163863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Freie Berichterstattung International</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-13-freieBeric...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9935429847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Regellese und Diskussionsgruppe zum Xavier's M...</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-13-xavierChat</td>\n",
       "      <td>private_supergroup</td>\n",
       "      <td>9907103286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>WIR sind VIEL mehr!</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-13-wirSindMehr</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9788772075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FreiDenker oder doch eher Freiraus Poster - 08...</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-15-freiDenker</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9836526551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Freiheitdergedanken</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-18-freiheitDe...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10013009712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Querdenken (711 - STUTTGART) - Wir fuer das Gr...</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-18-querdenken711</td>\n",
       "      <td>public_supergroup</td>\n",
       "      <td>9812812343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Holistische Gesundheit, Heilung und Aufklaerung</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-18-holistisch...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9758769198</td>\n",
       "      <td>not unique</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fakten Frieden Freiheit</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-20-faktenFrie...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9785934992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BabylonDecoded Wissen und Erbe fuer die Nachwe...</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-21-babylonDec...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>10002534295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Die Zuversicht, Kulturgut, Wissensbewahrung, A...</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-21-zuversicht...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9770976019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Holistisches Matrixdenken (uebergeordnet)</td>\n",
       "      <td>DS-22-10-2020/ChatExport_2020-10-21-holistisch...</td>\n",
       "      <td>public_channel</td>\n",
       "      <td>9894423174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            inputName  \\\n",
       "0                                      FREIHEITS-CHAT   \n",
       "1                           Oliver Janich oeffentlich   \n",
       "2                            ATTILA HILDMANN OFFICIAL   \n",
       "3                    Gerechtigkeit fuer das Vaterland   \n",
       "4                          Corona Virus Informationen   \n",
       "5                                             Liberte   \n",
       "6                                  Golden Age Network   \n",
       "7                                    Weltfrieden 2020   \n",
       "8                                     Verschwoerungen   \n",
       "9                               Digital Research Army   \n",
       "10                                        StefanRaven   \n",
       "11                               Eva Herman Offiziell   \n",
       "12                        Xavier Naidoo (inoffiziell)   \n",
       "13                                 Digitaler Chronist   \n",
       "14                                Das Prinz Telegramm   \n",
       "15                     Strahlenkranz V....Merci Danke   \n",
       "16  Wissensbewahrung Absicherung/Videokanal, Kultu...   \n",
       "17    Holistische Gesundheit, Heilung und Aufklaerung   \n",
       "18                                Metropol Chronicles   \n",
       "19                                       Kulturstudio   \n",
       "20  Medizinjournalist Rainer Taufertshoefer (oeffe...   \n",
       "21                 Die Deutsche Loesung - Aufklaerung   \n",
       "22                      Die deutsche Loesung - Gruppe   \n",
       "23                                     n8waechter.net   \n",
       "24                                 Deutsche Patrioten   \n",
       "25                            Patrioten im Widerstand   \n",
       "26                              FREIHEITSCHAT - BLITZ   \n",
       "27                                 Antiilluminaten TV   \n",
       "28                       DieWahrheitundnurdieWahrheit   \n",
       "29                                     ExpressZeitung   \n",
       "30                                         Unzensiert   \n",
       "31                                          Aufwachen   \n",
       "32                                    Gesundheitsecke   \n",
       "33                                Wissen ist Weisheit   \n",
       "34                                     QAnons Channel   \n",
       "35                                      Qanon Austria   \n",
       "36              Freie Berichterstattung International   \n",
       "37  Regellese und Diskussionsgruppe zum Xavier's M...   \n",
       "38                                WIR sind VIEL mehr!   \n",
       "39  FreiDenker oder doch eher Freiraus Poster - 08...   \n",
       "40                                Freiheitdergedanken   \n",
       "41  Querdenken (711 - STUTTGART) - Wir fuer das Gr...   \n",
       "42    Holistische Gesundheit, Heilung und Aufklaerung   \n",
       "43                            Fakten Frieden Freiheit   \n",
       "44  BabylonDecoded Wissen und Erbe fuer die Nachwe...   \n",
       "45  Die Zuversicht, Kulturgut, Wissensbewahrung, A...   \n",
       "46          Holistisches Matrixdenken (uebergeordnet)   \n",
       "\n",
       "                                            inputPath           inputType  \\\n",
       "0   DS-08-10-2020/ChatExport_2020-09-28-freiheitsChat   public_supergroup   \n",
       "1          DS-08-10-2020/ChatExport_2020-09-25-janich      public_channel   \n",
       "2        DS-08-10-2020/ChatExport_2020-09-25-hildmann      public_channel   \n",
       "3   DS-08-10-2020/ChatExport_2020-09-26-gerechtigk...      public_channel   \n",
       "4      DS-08-10-2020/ChatExport_2020-09-26-cvirusinfo      public_channel   \n",
       "5         DS-08-10-2020/ChatExport_2020-09-26-liberte      public_channel   \n",
       "6       DS-08-10-2020/ChatExport_2020-09-26-goldenage      public_channel   \n",
       "7   DS-08-10-2020/ChatExport_2020-09-26-weltfriede...      public_channel   \n",
       "8   DS-08-10-2020/ChatExport_2020-09-26-verschwoer...      public_channel   \n",
       "9   DS-08-10-2020/ChatExport_2020-09-27-digitalRes...      public_channel   \n",
       "10    DS-08-10-2020/ChatExport_2020-09-27-stefanraven      public_channel   \n",
       "11      DS-08-10-2020/ChatExport_2020-09-27-evaherman      public_channel   \n",
       "12         DS-08-10-2020/ChatExport_2020-09-25-xavier      public_channel   \n",
       "13  DS-08-10-2020/ChatExport_2020-09-29-digitalerC...      public_channel   \n",
       "14  DS-08-10-2020/ChatExport_2020-09-29-prinzTelegram      public_channel   \n",
       "15  DS-08-10-2020/ChatExport_2020-09-29-strahlenkranz      public_channel   \n",
       "16  DS-08-10-2020/ChatExport_2020-09-30-absicherun...      public_channel   \n",
       "17  DS-08-10-2020/ChatExport_2020-09-30-holistisch...      public_channel   \n",
       "18  DS-08-10-2020/ChatExport_2020-09-30-metropolChron      public_channel   \n",
       "19   DS-08-10-2020/ChatExport_2020-09-30-kulturstudio      public_channel   \n",
       "20  DS-08-10-2020/ChatExport_2020-09-30-rainerMedizin      public_channel   \n",
       "21  DS-08-10-2020/ChatExport_2020-09-30-deutscheAu...      public_channel   \n",
       "22    DS-08-10-2020/ChatExport_2020-09-30-deutscheLsg   public_supergroup   \n",
       "23  DS-08-10-2020/ChatExport_2020-10-01-nachtwaechter      public_channel   \n",
       "24  DS-08-10-2020/ChatExport_2020-10-01-deutschePatri   public_supergroup   \n",
       "25  DS-08-10-2020/ChatExport_2020-10-01-patriotenW...      public_channel   \n",
       "26  DS-08-10-2020/ChatExport_2020-10-01-freiheitsC...   public_supergroup   \n",
       "27  DS-08-10-2020/ChatExport_2020-10-02-antiillumi...      public_channel   \n",
       "28  DS-08-10-2020/ChatExport_2020-10-02-chatDieWah...   public_supergroup   \n",
       "29  DS-08-10-2020/ChatExport_2020-10-03-expressZei...      public_channel   \n",
       "30     DS-08-10-2020/ChatExport_2020-10-04-unzensiert      public_channel   \n",
       "31      DS-22-10-2020/ChatExport_2020-10-11-aufwachen      public_channel   \n",
       "32  DS-22-10-2020/ChatExport_2020-10-11-gesundheit...      public_channel   \n",
       "33  DS-22-10-2020/ChatExport_2020-10-12-wissenWeis...      public_channel   \n",
       "34  DS-22-10-2020/ChatExport_2020-10-12-qAnonsGermany      public_channel   \n",
       "35   DS-22-10-2020/ChatExport_2020-10-13-qanonAustria      public_channel   \n",
       "36  DS-22-10-2020/ChatExport_2020-10-13-freieBeric...      public_channel   \n",
       "37     DS-22-10-2020/ChatExport_2020-10-13-xavierChat  private_supergroup   \n",
       "38    DS-22-10-2020/ChatExport_2020-10-13-wirSindMehr   public_supergroup   \n",
       "39     DS-22-10-2020/ChatExport_2020-10-15-freiDenker   public_supergroup   \n",
       "40  DS-22-10-2020/ChatExport_2020-10-18-freiheitDe...      public_channel   \n",
       "41  DS-22-10-2020/ChatExport_2020-10-18-querdenken711   public_supergroup   \n",
       "42  DS-22-10-2020/ChatExport_2020-10-18-holistisch...      public_channel   \n",
       "43  DS-22-10-2020/ChatExport_2020-10-20-faktenFrie...      public_channel   \n",
       "44  DS-22-10-2020/ChatExport_2020-10-21-babylonDec...      public_channel   \n",
       "45  DS-22-10-2020/ChatExport_2020-10-21-zuversicht...      public_channel   \n",
       "46  DS-22-10-2020/ChatExport_2020-10-21-holistisch...      public_channel   \n",
       "\n",
       "        inputId   inputDesc inputDownloadType  \n",
       "0    9717909816         NaN               all  \n",
       "1    9808932799         NaN               all  \n",
       "2   10034163583         NaN               all  \n",
       "3   10069007089         NaN               all  \n",
       "4    9917074801         NaN               all  \n",
       "5   10068807626         NaN               all  \n",
       "6    9862302472         NaN               all  \n",
       "7    9850980068         NaN               all  \n",
       "8    9942502804         NaN               all  \n",
       "9    9846664545         NaN               all  \n",
       "10   9820850677         NaN               all  \n",
       "11   9915108907         NaN               all  \n",
       "12   9874390332         NaN               all  \n",
       "13  10068312319         NaN               all  \n",
       "14   9742969264         NaN               all  \n",
       "15  10050449614         NaN               all  \n",
       "16   9779767132         NaN               all  \n",
       "17   9758769198  not unique               all  \n",
       "18   9919682714         NaN               all  \n",
       "19  10064728094         NaN               all  \n",
       "20   9804874080         NaN               all  \n",
       "21   9927244279         NaN               all  \n",
       "22   9982253319         NaN               all  \n",
       "23   9744633492         NaN               all  \n",
       "24   9785040372         NaN               all  \n",
       "25   9913028741         NaN               all  \n",
       "26   9943834900         NaN               all  \n",
       "27  10060003597         NaN               all  \n",
       "28   9969119455         NaN               all  \n",
       "29   9857073102         NaN               all  \n",
       "30   9725746662         NaN               all  \n",
       "31   9683270591         NaN               all  \n",
       "32   9706227251         NaN               all  \n",
       "33   9691754437         NaN               all  \n",
       "34   9804534747         NaN               all  \n",
       "35   9962163863         NaN               all  \n",
       "36   9935429847         NaN               all  \n",
       "37   9907103286         NaN               all  \n",
       "38   9788772075         NaN               all  \n",
       "39   9836526551         NaN               all  \n",
       "40  10013009712         NaN               all  \n",
       "41   9812812343         NaN               all  \n",
       "42   9758769198  not unique               all  \n",
       "43   9785934992         NaN               all  \n",
       "44  10002534295         NaN               all  \n",
       "45   9770976019         NaN               all  \n",
       "46   9894423174         NaN               all  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfInputFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data into DataFrmaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame Meta (Chat Meta)\n",
    "def convertToDataFrameMeta(filePath):\n",
    "    dF = pd.read_json(dir_var + \"data/\" + filePath + \"/result.json\", encoding='utf-8')\n",
    "    return dF\n",
    "\n",
    "# Convert to DataFrame Messages (Chat Messages)\n",
    "def convertToDataFrameMessages(filePath, dictMeta):\n",
    "    dF = pd.json_normalize(dictMeta[filePath].messages)\n",
    "    return dF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get params from extractedTextData\n",
    "See cell below (key)\n",
    "\"\"\"\n",
    "def getExtractedTextDataParam(key, extractedTextData):\n",
    "    a,b,c,d,e,f,g = extractedTextData\n",
    "    switcher = {\n",
    "        0: a,\n",
    "        1: b,\n",
    "        2: c,\n",
    "        3: d,\n",
    "        4: e,\n",
    "        5: f,\n",
    "        6: g\n",
    "    }\n",
    "    return switcher.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: href, mention and hashtags in normal text?\n",
    "\n",
    "\"\"\"\n",
    "Extract text data (see cell above key)\n",
    "See cell above (key)\n",
    "\n",
    "param   procIsJsonFormatted Boolean (is text json formatted?)\n",
    "param   text                String  (text from message) \n",
    "\n",
    "return\n",
    "a   procText            Plain Text\n",
    "b   processedURLs       Array of URLs in Text\n",
    "c   processedHashtags   Array of Hashtags in Text\n",
    "d   processedBolds      Array of Bold Items in Text\n",
    "e   processedItalics    Array of Italic Items in Text\n",
    "f   processedUnderlines Array of Underlined Items in Text\n",
    "g   processedEmails     Array of E-Mails in Text\n",
    "\"\"\"\n",
    "def extractTextData(procIsJsonFormatted, text):\n",
    "    \n",
    "    # 3 returns in this function...\n",
    "    \n",
    "    processedURLs       = list()\n",
    "    processedHashtags   = list()\n",
    "    processedBolds      = list()\n",
    "    processedItalics    = list()\n",
    "    processedUnderlines = list()\n",
    "    processedEmails     = list()\n",
    "    \n",
    "    if(procIsJsonFormatted != True):\n",
    "        #Is not JSON formatted (return normal text)\n",
    "        return (text, processedURLs, processedHashtags, processedBolds, processedItalics, processedUnderlines, processedEmails)\n",
    "    else:\n",
    "        #Is is JSON formatted (try to parse)\n",
    "        try:\n",
    "            returnList = []\n",
    "            jsonList = demjson.decode(str(text), encoding='utf8')\n",
    "\n",
    "            # Do for each item in list\n",
    "            for lItem in jsonList:\n",
    "\n",
    "                messageString = str(lItem)\n",
    "\n",
    "                isJsonSubString = gloCheckIsTextJsonFormatted(messageString, singleMode = True)\n",
    "\n",
    "                if(isJsonSubString):\n",
    "                    # Is Json Sub String\n",
    "                    subJsonString = demjson.decode(str(messageString), encoding='utf8')\n",
    "                    subJsonType = subJsonString[\"type\"]\n",
    "\n",
    "                    if(subJsonType == \"bold\"):\n",
    "                        #text included\n",
    "                        processedBolds.append(subJsonString[\"text\"])\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"italic\"):\n",
    "                        #text included\n",
    "                        processedItalics.append(subJsonString[\"text\"])\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"underline\"):\n",
    "                        #text included\n",
    "                        processedUnderlines.append(subJsonString[\"text\"])\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                    \n",
    "                    elif(subJsonType == \"email\"):\n",
    "                        #text included\n",
    "                        processedEmails.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"text_link\"):\n",
    "                        #text and href included\n",
    "                        processedURLs.append(subJsonString[\"href\"])\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"link\"):\n",
    "                        #text included\n",
    "                        processedURLs.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"hashtag\"):\n",
    "                        #text included\n",
    "                        processedHashtags.append(subJsonString[\"text\"])\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"mention\"):\n",
    "                        #text included\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"mention_name\"):\n",
    "                        #text and user_id included\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"bot_command\"):\n",
    "                        #text included\n",
    "                        returnList = returnList \n",
    "                        \n",
    "                    elif(subJsonType == \"code\"):\n",
    "                        #text included\n",
    "                        returnList = returnList\n",
    "                        \n",
    "                    elif(subJsonType == \"phone\"):\n",
    "                        #text included\n",
    "                        returnList = returnList\n",
    "                        \n",
    "                    elif(subJsonType == \"strikethrough\"):\n",
    "                        #text included\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"pre\"):\n",
    "                        #text and language included\n",
    "                        returnList.append(subJsonString[\"text\"])\n",
    "                        \n",
    "                    elif(subJsonType == \"bank_card\"):\n",
    "                        #text included\n",
    "                        returnList = returnList\n",
    "                        \n",
    "                    else:\n",
    "                        print(\"- Error: Unkown json type >>\" + str(subJsonType) + \"<< (ignore) >>\" + str(text) + \"<<\")\n",
    "\n",
    "                else:\n",
    "                    # Is no json formatted sub string (append text)\n",
    "                    returnList.append(messageString)\n",
    "\n",
    "            return (''.join(returnList), processedURLs, processedHashtags, processedBolds, processedItalics, processedUnderlines, processedEmails)\n",
    "        \n",
    "        except:\n",
    "            # Parser error (set inputText to returnText)\n",
    "            print(\"- Warn: Json parser error (set inputText to returnText) >>\" + str(text) + \"<<\")\n",
    "            return (text, processedURLs, processedHashtags, processedBolds, processedItalics, processedUnderlines, processedEmails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalIsValidText(procTDTextLength):\n",
    "    if(procTDTextLength > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalContainsSomething(att):\n",
    "    if(str(att) == \"nan\"):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stopwatch started >>Extract Text Data<<]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-28-freiheitsChat<<]\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Nachweis hier einfügen]<<\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-28-freiheitsChat<< (259.688s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-25-janich<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-25-janich<< (85.783s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-25-hildmann<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-25-hildmann<< (29.729s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-gerechtigkeitVaterland<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-gerechtigkeitVaterland<< (1.396s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-cvirusinfo<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-cvirusinfo<< (12.020s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-liberte<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-liberte<< (5.479s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-goldenage<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-goldenage<< (6.009s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-weltfrieden2020<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-weltfrieden2020<< (4.716s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-verschwoerungen<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-26-verschwoerungen<< (11.661s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-27-digitalResearch<<]\n",
      "- Error: Unkown json type >>cashtag<< (ignore) >>['BREAKING: Tesla erleidet VOLLSTÄNDIGEN Netzwerkausfall - interne Systeme und Konnektivitätsfunktionen sind ausgefallen. ', {'type': 'cashtag', 'text': '$TSLA'}, '\\n\\n', {'type': 'link', 'text': 't.me/Q_D_R_A'}, '']<<\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-27-digitalResearch<< (41.889s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-27-stefanraven<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-27-stefanraven<< (2.280s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-27-evaherman<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-27-evaherman<< (53.867s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-25-xavier<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-25-xavier<< (16.349s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-29-digitalerChronist<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-29-digitalerChronist<< (6.789s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-29-prinzTelegram<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-29-prinzTelegram<< (6.853s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-29-strahlenkranz<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-29-strahlenkranz<< (56.629s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-absicherungNachwelt<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-absicherungNachwelt<< (0.961s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-holistischeGesundheit<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-holistischeGesundheit<< (9.576s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-metropolChron<<]\n",
      "- Warn: Add column >>photo<<\n",
      "- Warn: Add column >>file<<\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-metropolChron<< (1.120s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-kulturstudio<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-kulturstudio<< (24.097s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-rainerMedizin<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-rainerMedizin<< (13.615s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-deutscheAufklaerung<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-deutscheAufklaerung<< (1.192s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-deutscheLsg<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-09-30-deutscheLsg<< (6.896s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-nachtwaechter<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-nachtwaechter<< (0.538s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-deutschePatri<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-deutschePatri<< (2.422s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-patriotenWiderstand<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-patriotenWiderstand<< (5.294s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-freiheitsChatBlitz<<]\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Manchmal sagen Bilder mehr als tausend Worte..]<<\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Manchmal sagen Bilder mehr als tausend Worte..]<<\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Manchmal sagen Bilder mehr als tausend Worte..]<<\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Manchmal sagen Bilder mehr als tausend Worte..]<<\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-01-freiheitsChatBlitz<< (46.497s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-02-antiilluminaten<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-02-antiilluminaten<< (59.224s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-02-chatDieWahrheit<<]\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Typo oben: Firmen, nicht Formen :-D ]<<\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-02-chatDieWahrheit<< (90.861s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-03-expressZeitung<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-03-expressZeitung<< (17.185s)]\n",
      "[Stopwatch started >>TD-Extract DS-08-10-2020/ChatExport_2020-10-04-unzensiert<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-08-10-2020/ChatExport_2020-10-04-unzensiert<< (85.847s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-11-aufwachen<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-11-aufwachen<< (2.493s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-11-gesundheitsecke<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-11-gesundheitsecke<< (13.406s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-12-wissenWeisheit<<]\n",
      "- Warn: Json parser error (set inputText to returnText) >>[Systemsklaven]<<\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-12-wissenWeisheit<< (21.458s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-12-qAnonsGermany<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-12-qAnonsGermany<< (22.064s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-qanonAustria<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-qanonAustria<< (22.189s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-freieBerichtInt<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-freieBerichtInt<< (2.070s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-xavierChat<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-xavierChat<< (24.036s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-wirSindMehr<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-13-wirSindMehr<< (40.466s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-15-freiDenker<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-15-freiDenker<< (16.692s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-18-freiheitDerGedanken<<]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-18-freiheitDerGedanken<< (9.163s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-18-querdenken711<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-18-querdenken711<< (1.807s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-18-holistischeGesundheitHeilung<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-18-holistischeGesundheitHeilung<< (9.882s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-20-faktenFriedenFreiheit<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-20-faktenFriedenFreiheit<< (12.646s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-21-babylonDecoded<<]\n",
      "- Warn: Add column >>file<<\n",
      "- Warn: Add column >>forwarded_from<<\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-21-babylonDecoded<< (0.513s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-21-zuversichtWissensbewahrung<<]\n",
      "- Warn: Add column >>forwarded_from<<\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-21-zuversichtWissensbewahrung<< (0.730s)]\n",
      "[Stopwatch started >>TD-Extract DS-22-10-2020/ChatExport_2020-10-21-holistischesDenkenUeber<<]\n",
      "[Stopwatch stopped >>TD-Extract DS-22-10-2020/ChatExport_2020-10-21-holistischesDenkenUeber<< (1.405s)]\n",
      "[Stopwatch started >>Generate global DataFrame<<]\n",
      "[Stopwatch stopped >>Generate global DataFrame<< (109.288s)]\n",
      "[Stopwatch stopped >>Extract Text Data<< (1285.694s)]\n"
     ]
    }
   ],
   "source": [
    "gloStartStopwatch(\"Extract Text Data\")\n",
    "\n",
    "# Add Key = filePath / Value = DataFrame (Chat Meta)\n",
    "dictMeta = {}\n",
    "for fP in dfInputFiles.inputPath:\n",
    "    dictMeta[fP] = convertToDataFrameMeta(fP)\n",
    "\n",
    "# Add Key = filePath / Value = DataFrame (Chat Message)\n",
    "dictMessages = {}\n",
    "for fP in dfInputFiles.inputPath:\n",
    "\n",
    "    gloStartStopwatch(\"TD-Extract \" + fP)\n",
    "    dfMessages                          = convertToDataFrameMessages(fP, dictMeta)\n",
    "    \n",
    "    # Get chat attributes and check if message is json formatted\n",
    "    dfMessages[\"procChatFilePath\"]      = fP\n",
    "    dfMessages[\"procChatType\"]          = dictMeta[fP].type.iloc[0]\n",
    "    dfMessages[\"procIsJsonFormatted\"]   = dfMessages[\"text\"].apply(gloCheckIsTextJsonFormatted, singleMode = False)\n",
    "    \n",
    "    # Extract Text Data\n",
    "    dfMessages[\"tmpExtractedTD\"]        = dfMessages.apply(lambda x: extractTextData(x.procIsJsonFormatted, x.text), axis=1)\n",
    "\n",
    "    # Extract Text Data (params)\n",
    "    dfMessages[\"procTDText\"]            = dfMessages.apply(lambda x: getExtractedTextDataParam(0, x.tmpExtractedTD), axis=1)\n",
    "    dfMessages[\"procTDURLs\"]            = dfMessages.apply(lambda x: getExtractedTextDataParam(1, x.tmpExtractedTD), axis=1)\n",
    "    dfMessages[\"procTDHashtags\"]        = dfMessages.apply(lambda x: getExtractedTextDataParam(2, x.tmpExtractedTD), axis=1)\n",
    "    dfMessages[\"procTDBolds\"]           = dfMessages.apply(lambda x: getExtractedTextDataParam(3, x.tmpExtractedTD), axis=1)\n",
    "    dfMessages[\"procTDItalics\"]         = dfMessages.apply(lambda x: getExtractedTextDataParam(4, x.tmpExtractedTD), axis=1)\n",
    "    dfMessages[\"procTDUnderlines\"]      = dfMessages.apply(lambda x: getExtractedTextDataParam(5, x.tmpExtractedTD), axis=1)\n",
    "    dfMessages[\"procTDEmails\"]          = dfMessages.apply(lambda x: getExtractedTextDataParam(6, x.tmpExtractedTD), axis=1)\n",
    "\n",
    "    # Calc text size\n",
    "    dfMessages[\"procTDTextLength\"]      = dfMessages[\"procTDText\"].str.len()\n",
    "\n",
    "    # Add columns (if not exists)\n",
    "    if \"photo\" not in dfMessages:\n",
    "        print(\"- Warn: Add column >>photo<<\")\n",
    "        dfMessages[\"photo\"] = np.nan\n",
    "\n",
    "    if \"file\" not in dfMessages:\n",
    "        print(\"- Warn: Add column >>file<<\")\n",
    "        dfMessages[\"file\"] = np.nan\n",
    "\n",
    "    if \"edited\" not in dfMessages:\n",
    "        print(\"- Warn: Add column >>edited<<\")\n",
    "        dfMessages[\"edited\"] = np.nan\n",
    "\n",
    "    if \"forwarded_from\" not in dfMessages:\n",
    "        print(\"- Warn: Add column >>forwarded_from<<\")\n",
    "        dfMessages[\"forwarded_from\"] = np.nan\n",
    "\n",
    "    # Evaluate attributes\n",
    "    dfMessages[\"procEvalIsValidText\"]   = dfMessages.procTDTextLength.apply(evalIsValidText)\n",
    "    dfMessages[\"procEvalContainsPhoto\"] = dfMessages.photo.apply(evalContainsSomething)\n",
    "    dfMessages[\"procEvalContainsFile\"]  = dfMessages.file.apply(evalContainsSomething) \n",
    "    dfMessages[\"procEvalIsEdited\"]      = dfMessages.edited.apply(evalContainsSomething)\n",
    "    dfMessages[\"procEvalIsForwarded\"]   = dfMessages.forwarded_from.apply(evalContainsSomething)\n",
    "    # TODO: Add more attributes (e.g. procEvalContainBoldItems)\n",
    "    \n",
    "    dictMessages[fP] = dfMessages\n",
    "    gloStopStopwatch(\"TD-Extract \" + fP)\n",
    "\n",
    "    \n",
    "# All Messages to DataFrame\n",
    "gloStartStopwatch(\"Generate global DataFrame\")\n",
    "dfAllDataMessages = pd.DataFrame()\n",
    "for fP in dfInputFiles.inputPath:\n",
    "    dfMessages        = dictMessages[fP].copy()\n",
    "    dfAllDataMessages = dfAllDataMessages.append(dfMessages)\n",
    "gloStopStopwatch(\"Generate global DataFrame\")\n",
    "\n",
    "gloStopStopwatch(\"Extract Text Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of channels (and only included in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_channel        38\n",
       "public_supergroup      8\n",
       "private_supergroup     1\n",
       "Name: inputType, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfInputFiles.inputType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfAllDataMessages.columns.difference(dfAllDataMessages[dfAllDataMessages.procChatType == \"public_channel\"].dropna(how='all', axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dfAllDataMessages.columns.difference(dfAllDataMessages[dfAllDataMessages.procChatType == \"public_supergroup\"].dropna(how='all', axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No enough data\n",
    "#dfAllDataMessages.columns.difference(dfAllDataMessages[dfAllDataMessages.procChatType == \"private_supergroup\"].dropna(how='all', axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryChatId(filePath):\n",
    "    dfMeta = dictMeta[filePath].copy()\n",
    "    return str(dfMeta[\"id\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryChatName(filePath):\n",
    "    dfMeta      = dictMeta[filePath].copy()\n",
    "    chatName    = str(dfMeta[\"name\"].iloc[0])\n",
    "    chatName    = gloConvertToSafeChatName(chatName)\n",
    "    return chatName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryChatType(filePath):\n",
    "    dfMeta = dictMeta[filePath].copy()\n",
    "    return str(dfMeta[\"type\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfMessages(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfFormattedTextMessages(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.procIsJsonFormatted == True]\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfValidTextMessages(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.procEvalIsValidText == True]\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfPhotos(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.procEvalContainsPhoto == True]\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfFiles(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.procEvalContainsFile == True]\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfEditedMessages(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.procEvalIsEdited == True]\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryNumberOfForwardedMessages(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.procEvalIsForwarded == True]\n",
    "    return len(dfMessages.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQueryMeta = pd.DataFrame(dfInputFiles.inputPath)\n",
    "\n",
    "dfQueryMeta[\"qryChatId\"]                        = dfQueryMeta.inputPath.apply(queryChatId)\n",
    "dfQueryMeta[\"qryChatName\"]                      = dfQueryMeta.inputPath.apply(queryChatName)\n",
    "dfQueryMeta[\"qryChatType\"]                      = dfQueryMeta.inputPath.apply(queryChatType)\n",
    "dfQueryMeta[\"qryNumberOfMessages\"]              = dfQueryMeta.inputPath.apply(queryNumberOfMessages)\n",
    "dfQueryMeta[\"qryNumberOfFormattedTextMessages\"] = dfQueryMeta.inputPath.apply(queryNumberOfFormattedTextMessages)\n",
    "dfQueryMeta[\"qryNumberOfValidTextMessages\"]     = dfQueryMeta.inputPath.apply(queryNumberOfValidTextMessages)\n",
    "dfQueryMeta[\"qryNumberOfPhotos\"]                = dfQueryMeta.inputPath.apply(queryNumberOfPhotos)\n",
    "dfQueryMeta[\"qryNumberOfFiles\"]                 = dfQueryMeta.inputPath.apply(queryNumberOfFiles)\n",
    "dfQueryMeta[\"qryNumberOfEditedMessages\"]        = dfQueryMeta.inputPath.apply(queryNumberOfEditedMessages)\n",
    "dfQueryMeta[\"qryNumberOfForwardedMessages\"]     = dfQueryMeta.inputPath.apply(queryNumberOfForwardedMessages)\n",
    "\n",
    "dfQueryMeta.sort_values(by=\"qryNumberOfMessages\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot meta queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto label query plot\n",
    "def autolabelAx(rects, ax):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar in *rects*, displaying its height.\n",
    "    Copied from https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html (22.12.2020)\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryMetaPlotter():\n",
    "    # Init data\n",
    "    dataLabels                          = list()\n",
    "    dataNumberOfMesssages               = list()\n",
    "    dataNumberOfFormattedTextMessages   = list()\n",
    "    dataNumberOfValidTextMessages       = list()\n",
    "    dataNumberOfEditedMessages          = list()\n",
    "    dataNumberOfPhotos                  = list()\n",
    "    dataNumberOfFiles                   = list()\n",
    "    dataNumberOfForwardedMessages       = list()\n",
    "\n",
    "    # Iterate over Meta DataFrame\n",
    "    for index, row in dfQueryMeta.sort_values(by=\"qryNumberOfMessages\", ascending=False).iterrows():\n",
    "\n",
    "        # Get attributes\n",
    "        dataLabels                          .append(row.qryChatName)\n",
    "        dataNumberOfMesssages               .append(row.qryNumberOfMessages)\n",
    "        dataNumberOfFormattedTextMessages   .append(row.qryNumberOfFormattedTextMessages)\n",
    "        dataNumberOfValidTextMessages       .append(row.qryNumberOfValidTextMessages)\n",
    "        dataNumberOfEditedMessages          .append(row.qryNumberOfEditedMessages)\n",
    "        dataNumberOfPhotos                  .append(row.qryNumberOfPhotos)\n",
    "        dataNumberOfFiles                   .append(row.qryNumberOfFiles)\n",
    "        dataNumberOfForwardedMessages       .append(row.qryNumberOfForwardedMessages)\n",
    "\n",
    "    # Convert list to array\n",
    "    dataLabels                          = np.array(dataLabels)\n",
    "    dataNumberOfMesssages               = np.array(dataNumberOfMesssages)\n",
    "    dataNumberOfFormattedTextMessages   = np.array(dataNumberOfFormattedTextMessages)\n",
    "    dataNumberOfValidTextMessages       = np.array(dataNumberOfValidTextMessages)\n",
    "    dataNumberOfEditedMessages          = np.array(dataNumberOfEditedMessages)\n",
    "    dataNumberOfPhotos                  = np.array(dataNumberOfPhotos)\n",
    "    dataNumberOfFiles                   = np.array(dataNumberOfFiles)\n",
    "    dataNumberOfForwardedMessages       = np.array(dataNumberOfForwardedMessages)\n",
    "\n",
    "    # Draw\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(len(dataLabels))\n",
    "\n",
    "    barWidth = 0.1\n",
    "\n",
    "    fig.set_figwidth(64)\n",
    "    fig.set_figheight(16)\n",
    "\n",
    "    r1 = x\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "    r4 = [x + barWidth for x in r3]\n",
    "    r5 = [x + barWidth for x in r4]\n",
    "    r6 = [x + barWidth for x in r5]\n",
    "    r7 = [x + barWidth for x in r6]\n",
    "\n",
    "    rects1 = ax.bar(r1, dataNumberOfMesssages, barWidth, label='Messages')\n",
    "    rects2 = ax.bar(r2, dataNumberOfFormattedTextMessages, barWidth, label='Formatted Messsages')\n",
    "    rects3 = ax.bar(r3, dataNumberOfValidTextMessages, barWidth, label='Valid Messages')\n",
    "    rects4 = ax.bar(r4, dataNumberOfEditedMessages, barWidth, label='Edited Messages')\n",
    "    rects5 = ax.bar(r5, dataNumberOfPhotos, barWidth, label='with Photo')\n",
    "    rects6 = ax.bar(r6, dataNumberOfFiles, barWidth, label='with File')\n",
    "    rects7 = ax.bar(r7, dataNumberOfForwardedMessages, barWidth, label='Forwarded Messages')\n",
    "\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(\"Meta Overview\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(dataLabels)\n",
    "    ax.legend()\n",
    "\n",
    "    rects = [rects1, rects2, rects3, rects4, rects5, rects6, rects7]\n",
    "\n",
    "    for rect in rects:\n",
    "        autolabelAx(rect, ax)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.savefig(dir_var_output + \"meta-overview.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMetaPlotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTextLengthOutliersFromDataFrame(df, interval, maxTextLength):\n",
    "    df = df.copy()\n",
    "    df = df[df.procTDTextLength < maxTextLength]\n",
    "    # https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "    # keep only the ones that are within <interval> to -<interval> standard deviations in the column 'Data'.\n",
    "    return df[np.abs(df.procTDTextLength-df.procTDTextLength.mean()) <= (interval*df.procTDTextLength.std())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textLengthHistPlotter():\n",
    "    dfMessages = dfAllDataMessages.copy()\n",
    "    print(\"Number of all messages:\\t\\t\\t\\t\\t\\t\" + str(len(dfMessages.index)))\n",
    "\n",
    "    dfMessages = dfMessages[dfMessages.procEvalIsValidText == True]\n",
    "    print(\"Number of valid text messages:\\t\\t\\t\\t\\t\" + str(len(dfMessages.index)))\n",
    "\n",
    "    dfMessages = removeTextLengthOutliersFromDataFrame(\n",
    "        dfMessages,\n",
    "        interval = 3,         #default is 3\n",
    "        maxTextLength = 750\n",
    "        )\n",
    "    print(\"Number of valid text messages (after outliers filtering):\\t\" + str(len(dfMessages.index)))\n",
    "\n",
    "    print()\n",
    "    print(\"Text Length Hist (after outliers filtering)\")\n",
    "    plt.figure(figsize=(16,9))\n",
    "    _ = dfMessages.procTDTextLength.hist(bins=10)\n",
    "\n",
    "    plt.savefig(dir_var_output + \"meta-text-length-hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textLengthHistPlotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Important Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract hashtags in non formatted text\n",
    "\n",
    "def extractImportantHashtags(filePath):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "    dfMessages = dfMessages[dfMessages.astype(str)[\"procTDHashtags\"] != \"[]\"]\n",
    "\n",
    "    hashTagList = list()\n",
    "    for index, row in dfMessages.iterrows():\n",
    "        for hashtagItem in row[\"procTDHashtags\"]:\n",
    "            hashTagList.append(hashtagItem)\n",
    "\n",
    "    return Counter(hashTagList).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractImportantHashtags(\"DS-08-10-2020/ChatExport_2020-09-25-janich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractImportantHashtags(\"DS-08-10-2020/ChatExport_2020-09-27-evaherman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractImportantHashtags(\"DS-08-10-2020/ChatExport_2020-09-25-hildmann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractImportantHashtags(\"DS-08-10-2020/ChatExport_2020-09-25-xavier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Social Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Bug: No Hostname detected if string startsWith ! \"http\" in urlparse\n",
    "# TODO: Feature: Url in non formatted text?\n",
    "# TODO: Feature: Add other attributes (e.g. hashtags)\n",
    "# TODO: Feature: Cache-Layer: Check if both set (from and from_id, actor, ...)\n",
    "# TODO: Check: Duplicates refs from text\n",
    "\n",
    "# TODO: Doc: Text ref important for finding groups\n",
    "# TODO: Doc: forwared_from important for graphs\n",
    "\n",
    "# Return Counter forwarded_from\n",
    "def extractSocialGraph(filePath, debugPrint):\n",
    "    dfMessages = dictMessages[filePath].copy()\n",
    "\n",
    "    hostList = list()\n",
    "    urList   = list()\n",
    "    refList = list()\n",
    "    for index, row in dfMessages.iterrows():\n",
    "        if(str(row[\"procTDURLs\"]) != \"[]\"):\n",
    "            for urlItem in row[\"procTDURLs\"]:\n",
    "                urlData = urlparse(str(urlItem))\n",
    "\n",
    "                completeHostname = urlData.hostname\n",
    "                completeUrl      = urlData.geturl()\n",
    "\n",
    "                hostList.append(str(completeHostname))\n",
    "                urList.append(str(completeUrl))\n",
    "\n",
    "                if \"t.me\" in str(completeHostname):\n",
    "                    refList.append(str(completeUrl))\n",
    "            \n",
    "    forwardedFromList = list()\n",
    "    if(\"forwarded_from\" in dfMessages.columns):\n",
    "        for index, row in dfMessages.iterrows():        \n",
    "            forwardedFromList.append(str(row[\"forwarded_from\"]))\n",
    "            \n",
    "    actorList = list()\n",
    "    if(\"actor\" in dfMessages.columns):\n",
    "        for index, row in dfMessages.iterrows():\n",
    "            actorList.append(str(row[\"actor\"]))\n",
    "    \n",
    "    memberList = list()\n",
    "    if(\"members\" in dfMessages.columns):\n",
    "        for index, row in dfMessages.iterrows():\n",
    "            if(str(row[\"members\"]) != \"nan\"):\n",
    "                for memberItem in row[\"members\"]:\n",
    "                    memberList.append(str(memberItem))\n",
    "                    \n",
    "    fromList = list()\n",
    "    if(\"from\" in dfMessages.columns):\n",
    "        for index, row in dfMessages.iterrows():\n",
    "            fromList.append(str(row[\"from\"]))\n",
    "            \n",
    "    savedFromList = list()\n",
    "    if(\"saved_from\" in dfMessages.columns):\n",
    "        for index, row in dfMessages.iterrows():\n",
    "            savedFromList.append(str(row[\"saved_from\"]))\n",
    "        \n",
    "    if(debugPrint):\n",
    "        print(\"- Top 20 Hosts -\")\n",
    "        print (\"\\n\".join(map(str, Counter(hostList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 URLs -\")\n",
    "        print (\"\\n\".join(map(str, Counter(urList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 Refs from text -\")\n",
    "        print (\"\\n\".join(map(str, Counter(refList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 Refs (forwarded_from) -\")\n",
    "        print (\"\\n\".join(map(str, Counter(forwardedFromList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 Refs (actor) -\")\n",
    "        print (\"\\n\".join(map(str, Counter(actorList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 Refs (members) -\")\n",
    "        print (\"\\n\".join(map(str, Counter(memberList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 Refs (from) -\")\n",
    "        print (\"\\n\".join(map(str, Counter(fromList).most_common(20))))\n",
    "        print()\n",
    "        print(\"- Top 20 Refs (saved_from) -\")\n",
    "        print (\"\\n\".join(map(str, Counter(savedFromList).most_common(20))))\n",
    "        print()\n",
    "    \n",
    "    return Counter(forwardedFromList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = extractSocialGraph(\"DS-08-10-2020/ChatExport_2020-09-25-janich\", debugPrint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = extractSocialGraph(\"DS-08-10-2020/ChatExport_2020-09-27-evaherman\", debugPrint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = extractSocialGraph(\"DS-08-10-2020/ChatExport_2020-09-25-hildmann\", debugPrint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = extractSocialGraph(\"DS-08-10-2020/ChatExport_2020-09-25-xavier\", debugPrint = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Social Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Refactor\n",
    "\n",
    "# Only add node size greater than\n",
    "def addSocialGraphNodeSize(label, newSize, targetDict):\n",
    "    \n",
    "    if(label in targetDict):\n",
    "        oldSize = targetDict[label]\n",
    "        if(newSize > oldSize):\n",
    "            targetDict[label] = newSize\n",
    "    else:\n",
    "        targetDict[label] = newSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Nan?\n",
    "# TODO: https://networkx.org/documentation/stable/reference/drawing.html#module-networkx.drawing.layout\n",
    "# TODO: (try different layouts e.g. circular_layout)\n",
    "# TODO: Dont add empty group names (no ref!)    \n",
    "# TODO: Check distances\n",
    "\n",
    "\"\"\"\n",
    "Generate social graph\n",
    "\n",
    "param   configTopNInfluencer    e.g. For top 10 = 10\n",
    "param   configMinRefs           e.g. 1 must have > 1 % forwarded messages\n",
    "\"\"\"\n",
    "def generateSocialGraph(configTopNInfluencer, configMinRefs):\n",
    "    \n",
    "    dictSocialNodeSizes = dict()\n",
    "    listExactValues     = list()\n",
    "    \n",
    "    gloStartStopwatch(\"Social Graph\")\n",
    "    \n",
    "    #Use Graph instead of DiGraph (Converted by draw)\n",
    "    G_weighted = nx.DiGraph()\n",
    "    \n",
    "    print(\"- Add edges\")\n",
    "    for fP in dfInputFiles.inputPath:\n",
    "        \n",
    "        chatName                        = queryChatName(fP)\n",
    "        chatNumberOfMessages            = queryNumberOfMessages(fP)\n",
    "        chatNumberOfForwardeMessages    = queryNumberOfForwardedMessages(fP)\n",
    "\n",
    "        gloStartStopwatch(\"SG-Extract \" + chatName + \"(\" + str(chatNumberOfMessages) + \" messages)\")\n",
    "        \n",
    "        # Add Correct Node Size (data downloaded)\n",
    "        addSocialGraphNodeSize(chatName, chatNumberOfMessages, dictSocialNodeSizes)\n",
    "        listExactValues.append(chatName)\n",
    "\n",
    "        # Get Graph Data\n",
    "        socialGraphData = extractSocialGraph(fP, debugPrint=False)\n",
    "        socialGraphData = socialGraphData.most_common(configTopNInfluencer)\n",
    "        \n",
    "        for oChatName, oChatRefs in socialGraphData:\n",
    "            \n",
    "            oChatName    = gloConvertToSafeChatName(str(oChatName))\n",
    "            oChatRefs    = oChatRefs\n",
    "\n",
    "            if(oChatName != \"nan\"):\n",
    "        \n",
    "                per = (oChatRefs/chatNumberOfForwardeMessages) * 100\n",
    "\n",
    "                if(per > configMinRefs):\n",
    "                \n",
    "                    # Add Incorrect Node Size (no data downloaded)\n",
    "                    addSocialGraphNodeSize(oChatName, oChatRefs, dictSocialNodeSizes)\n",
    "\n",
    "                    wei = 100 - per\n",
    "\n",
    "                    # Add Edge\n",
    "                    G_weighted.add_edge(\n",
    "                        chatName,\n",
    "                        oChatName,\n",
    "                        weight=wei,\n",
    "                        tLabel = str(round(per, 3)) + \"% (\" + str(oChatRefs) + \"/\" + str(chatNumberOfForwardeMessages) + \"≙\" + str(round(wei, 3)) + \")\"\n",
    "                        #tLabel = str(round(per, 3)) + \"%\"\n",
    "                    )\n",
    "\n",
    "        gloStopStopwatch(\"SG-Extract \" + chatName + \"(\" + str(chatNumberOfMessages) + \" messages)\")\n",
    "        \n",
    "    print(\"- Add different node sizes\")\n",
    "    for aNode in dictSocialNodeSizes:\n",
    "        \n",
    "        nodeName = str(aNode)\n",
    "        nodeSize = dictSocialNodeSizes[aNode]\n",
    "\n",
    "        tValueColor = \"#ff8000\"\n",
    "\n",
    "        if(nodeName in listExactValues):\n",
    "            tValueColor = \"#0080ff\"\n",
    "        \n",
    "        G_weighted.add_node(\n",
    "            nodeName,\n",
    "            weight=nodeSize,\n",
    "            tLabel = str(nodeName) + \" [\" + str(nodeSize) + \"]\",\n",
    "            tColor=tValueColor\n",
    "        )\n",
    "        \n",
    "    gloStopStopwatch(\"Social Graph\")\n",
    "        \n",
    "    return G_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Draw social media plot\n",
    "\n",
    "param   G                           graph\n",
    "param   configFactorEdge            e.g. 100 => weight / 100\n",
    "param   configFactorNode            e.g. 10  => weight / 10\n",
    "param   configArrowSize             e.g. 5\n",
    "param   configPlotWidth             e.g. 16\n",
    "param   configPlotHeight            e.g. 9\n",
    "param   outputFilename              e.g. test.png\n",
    "\"\"\"\n",
    "def drawSocialPlot(G, configFactorEdge, configFactorNode, configArrowSize, configPlotWidth, configPlotHeight, outputFilename):\n",
    "    \n",
    "    gloStartStopwatch(\"Social Graph Plot\")\n",
    "    \n",
    "    plt.figure(figsize=(configPlotWidth,configPlotHeight))\n",
    "        \n",
    "    #pos = nx.nx_pydot.graphviz_layout(G)\n",
    "    #pos = nx.spring_layout(G.to_undirected(), k = 0.15, iterations=200)\n",
    "    pos = nx.kamada_kawai_layout(G.to_undirected())\n",
    "    \n",
    "    # Clean edges\n",
    "    edges       = nx.get_edge_attributes(G, \"weight\")\n",
    "    edgesTLabel = nx.get_edge_attributes(G, \"tLabel\")\n",
    "\n",
    "    clean_edges         = dict()\n",
    "    clean_edges_labels  = dict()\n",
    "    \n",
    "    for key in edges:\n",
    "        \n",
    "        #Set line weight\n",
    "        clean_edges[key]        = (100 - edges[key]) / configFactorEdge\n",
    "\n",
    "        #set label\n",
    "        clean_edges_labels[key] = edgesTLabel[key]\n",
    "    \n",
    "    # Clean nodes\n",
    "    nodes       = nx.get_node_attributes(G,'weight')\n",
    "    nodesTLabel = nx.get_node_attributes(G,'tLabel')\n",
    "    nodesTColor = nx.get_node_attributes(G,'tColor')\n",
    "\n",
    "    clean_nodes         = dict()\n",
    "    clean_nodes_labels  = dict()\n",
    "    clean_nodes_color   = dict()\n",
    "    \n",
    "    for key in nodes:\n",
    "        \n",
    "        #Set Node weight        \n",
    "        clean_nodes[key]        = nodes[key] / configFactorNode\n",
    "\n",
    "        #Set Node layout\n",
    "        clean_nodes_labels[key] = nodesTLabel[key]\n",
    "        clean_nodes_color[key]  = nodesTColor[key]\n",
    "    \n",
    "    # Revert DiGraph (arrows direction)\n",
    "    G_rev = nx.DiGraph.reverse(G)    \n",
    "\n",
    "    nx.draw(G_rev,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        width=list(clean_edges.values()),\n",
    "        node_size=list(clean_nodes.values()),\n",
    "        labels=clean_nodes_labels,\n",
    "        node_color=list(clean_nodes_color.values()),\n",
    "        arrowsize=configArrowSize,\n",
    "        arrowstyle=\"wedge\" #TODO: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.patches.ArrowStyle.html\n",
    "        #connectionstyle=\"arc3, rad = 0.1\"\n",
    "    )\n",
    "        \n",
    "    _ = nx.draw_networkx_edge_labels(G_rev, pos, edge_labels=clean_edges_labels)\n",
    "\n",
    "    plt.savefig(dir_var_output + outputFilename)\n",
    "    plt.show()\n",
    "    \n",
    "    gloStopStopwatch(\"Social Graph Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates Test Graph\n",
    "def generateTestGraph():\n",
    "\n",
    "    #Use Graph instead of DiGraph\n",
    "    G_weighted = nx.DiGraph()\n",
    "\n",
    "    G_weighted.add_edge(\"N1\", \"N2\", weight=100-30,  tLabel = \"(≙\" + str(100-30) + \")\")\n",
    "    G_weighted.add_edge(\"N1\", \"N3\", weight=100-10,  tLabel = \"(≙\" + str(100-10) + \")\")\n",
    "    G_weighted.add_edge(\"N1\", \"N4\", weight=100-60,  tLabel = \"(≙\" + str(100-60) + \")\")\n",
    "\n",
    "    G_weighted.add_edge(\"N4\", \"N5\", weight=100-80,  tLabel = \"(≙\" + str(100-80) + \")\")\n",
    "    G_weighted.add_edge(\"N4\", \"N6\", weight=100-10,  tLabel = \"(≙\" + str(100-10) + \")\")\n",
    "\n",
    "    G_weighted.add_edge(\"N4\", \"N7\", weight=100-30,   tLabel = \"(≙\" + str(100-30) + \")\")\n",
    "    G_weighted.add_edge(\"N7\", \"N4\", weight=100-70,   tLabel = \"(≙\" + str(100-70) + \")\")\n",
    "\n",
    "    G_weighted.add_node(\"N1\", weight=500.0, tLabel = \"N1-T\", tColor=\"red\")\n",
    "    G_weighted.add_node(\"N2\", weight=500.0, tLabel = \"N2-T\", tColor=\"blue\")\n",
    "    G_weighted.add_node(\"N3\", weight=500.0, tLabel = \"N3-T\", tColor=\"blue\")\n",
    "    G_weighted.add_node(\"N4\", weight=500.0, tLabel = \"N4-T\", tColor=\"red\")\n",
    "    G_weighted.add_node(\"N5\", weight=500.0, tLabel = \"N5-T\", tColor=\"red\")\n",
    "    G_weighted.add_node(\"N6\", weight=500.0, tLabel = \"N6-T\", tColor=\"red\")\n",
    "    G_weighted.add_node(\"N7\", weight=500.0, tLabel = \"N7-T\", tColor=\"blue\")\n",
    "\n",
    "    return G_weighted\n",
    "\n",
    "generatedTestGraph = generateTestGraph()\n",
    "\n",
    "drawSocialPlot(\n",
    "    generatedTestGraph,\n",
    "    configFactorEdge = 10,\n",
    "    configFactorNode = 1,\n",
    "    configArrowSize = 15,\n",
    "    configPlotWidth = 16,\n",
    "    configPlotHeight = 9,\n",
    "    outputFilename = \"social-test-graph.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedSocialGraph = generateSocialGraph(\n",
    "    configTopNInfluencer = 50,  # TODO: Refactor\n",
    "    configMinRefs = 1,          # TODO: Refactor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Graph\n",
    "drawSocialPlot(\n",
    "    generatedSocialGraph,\n",
    "    configFactorEdge = 100,\n",
    "    configFactorNode = 1,\n",
    "    configArrowSize = 15,\n",
    "    configPlotWidth = 32,\n",
    "    configPlotHeight = 32,\n",
    "    outputFilename = \"social-graph.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Difference capital letters?\n",
    "# TODO: Context?\n",
    "# TODO: Improve stop words\n",
    "# TODO: Only on valid text?\n",
    "\n",
    "\"\"\"\n",
    "WordCloud\n",
    "\n",
    "param   filePath    String (set to \"global\" if you want to process all messages)\n",
    "param   label       filename in outputdir\n",
    "param   filterList  Exclude list\n",
    "\"\"\"\n",
    "\n",
    "def plotWordCloud(filePath, label, filterList):\n",
    "    \n",
    "    gloStartStopwatch(\"Word Cloud\")\n",
    "\n",
    "    if(filePath != \"global\"):\n",
    "        dfMessages = dictMessages[filePath].copy()\n",
    "    else:\n",
    "        dfMessages = dfAllDataMessages.copy()\n",
    "    \n",
    "    print(\"- Start transform text to global text string\")\n",
    "    textList = []\n",
    "    for index, row in dfMessages.iterrows():\n",
    "        textList.append(\" \" + row[\"procTDText\"])\n",
    "        \n",
    "    textString = ''.join(textList)\n",
    "    \n",
    "    germanStopWordsList = nltk.corpus.stopwords.words('german')\n",
    "    germanStopWordsList.append(\"http\")\n",
    "    germanStopWordsList.append(\"https\")\n",
    "    germanStopWordsList.append(\"ja\")\n",
    "    germanStopWordsList.append(\"nein\")\n",
    "    germanStopWordsList.append(\"mehr\")\n",
    "    germanStopWordsList.append(\"mal\")\n",
    "    germanStopWordsList.append(\"schon\")\n",
    "    germanStopWordsList.append(\"immer\")\n",
    "    germanStopWordsList.append(\"wurde\")\n",
    "    germanStopWordsList.append(\"wurden\")\n",
    "    germanStopWordsList.append(\"sei\")\n",
    "    germanStopWordsList.append(\"sein\")\n",
    "    germanStopWordsList.append(\"viel\")\n",
    "    germanStopWordsList.append(\"viele\")\n",
    "    germanStopWordsList.append(\"wegen\")\n",
    "    germanStopWordsList.append(\"müssen\")\n",
    "    germanStopWordsList.append(\"geht\")\n",
    "    germanStopWordsList.append(\"gibt\")\n",
    "    germanStopWordsList.append(\"wer\")\n",
    "    germanStopWordsList.append(\"wie\")\n",
    "    germanStopWordsList.append(\"was\")\n",
    "    germanStopWordsList.append(\"macht\")\n",
    "    germanStopWordsList.append(\"machen\")\n",
    "    germanStopWordsList.append(\"machte\")\n",
    "    germanStopWordsList.append(\"kommen\")\n",
    "    germanStopWordsList.append(\"kommt\")\n",
    "    germanStopWordsList.append(\"glaube\")\n",
    "    germanStopWordsList.append(\"glaubst\")\n",
    "    germanStopWordsList.append(\"tun\")\n",
    "    germanStopWordsList.append(\"wäre\")\n",
    "    germanStopWordsList.append(\"sagte\")\n",
    "    germanStopWordsList.append(\"sagten\")\n",
    "    germanStopWordsList.append(\"hat\")\n",
    "    germanStopWordsList.append(\"hast\")\n",
    "    germanStopWordsList.append(\"haben\")\n",
    "    germanStopWordsList.append(\"habt\")\n",
    "    germanStopWordsList.append(\"statt\")\n",
    "    germanStopWordsList.append(\"genau\")\n",
    "    germanStopWordsList.append(\"sagen\")\n",
    "    germanStopWordsList.append(\"sagte\")\n",
    "    germanStopWordsList.append(\"sagten\")\n",
    "    germanStopWordsList.append(\"bitte\")\n",
    "    germanStopWordsList.append(\"bitten\")\n",
    "    germanStopWordsList.append(\"danke\")\n",
    "    germanStopWordsList.append(\"dank\")\n",
    "    germanStopWordsList.append(\"sollen\")\n",
    "    germanStopWordsList.append(\"soll\")\n",
    "    germanStopWordsList.append(\"sollte\")\n",
    "    germanStopWordsList.append(\"sehen\")\n",
    "    germanStopWordsList.append(\"seht\")\n",
    "    germanStopWordsList.append(\"zeigen\")\n",
    "    germanStopWordsList.append(\"zeigt\")\n",
    "    germanStopWordsList.append(\"sei\")\n",
    "    germanStopWordsList.append(\"sein\")\n",
    "    germanStopWordsList.append(\"seid\")\n",
    "    germanStopWordsList.append(\"seit\")\n",
    "    germanStopWordsList.append(\"laut\")\n",
    "    germanStopWordsList.append(\"lauten\")\n",
    "    germanStopWordsList.append(\"sehen\")\n",
    "    germanStopWordsList.append(\"seht\")\n",
    "    germanStopWordsList.append(\"haben\")\n",
    "    germanStopWordsList.append(\"hat\")\n",
    "    germanStopWordsList.append(\"hätten\")\n",
    "    germanStopWordsList.append(\"sagte\")\n",
    "    germanStopWordsList.append(\"sag\")\n",
    "    germanStopWordsList.append(\"sagt\")\n",
    "    germanStopWordsList.append(\"ab\")\n",
    "    germanStopWordsList.append(\"bei\")\n",
    "    germanStopWordsList.append(\"beim\")\n",
    "    germanStopWordsList.append(\"denen\")\n",
    "    germanStopWordsList.append(\"gab\")\n",
    "    germanStopWordsList.append(\"ab\")\n",
    "    \n",
    "    for fItem in filterList:\n",
    "        germanStopWordsList.append(fItem)\n",
    "    \n",
    "    print(\"- Start generate cloud\")\n",
    "    wordcloud = WordCloud(\n",
    "                background_color=\"black\",\n",
    "                width=1920,\n",
    "                height=1080,\n",
    "                stopwords=germanStopWordsList\n",
    "            ).generate(textString)\n",
    "    wordcloud.to_file(dir_var_output + \"wordcloud-\" + label + \".png\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Top 20 occ:\\n\" + str(pd.Series(wordcloud.words_).head(20)))\n",
    "    print()\n",
    "    \n",
    "    print(\"- Start generate figure\")\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.show()\n",
    "    \n",
    "    gloStopStopwatch(\"Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oliver Janich öffentlich (public_channel)\n",
    "plotWordCloud(\n",
    "    \"DS-08-10-2020/ChatExport_2020-09-25-janich\",\n",
    "    \"pc-janich\",\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eva Herman Offiziell (public_channel)\n",
    "plotWordCloud(\n",
    "    \"DS-08-10-2020/ChatExport_2020-09-27-evaherman\",\n",
    "    \"pc-evaHerman\",\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTILA HILDMANN OFFICIAL (public_channel)\n",
    "plotWordCloud(\n",
    "    \"DS-08-10-2020/ChatExport_2020-09-25-hildmann\",\n",
    "    \"pc-hildmann\",\n",
    "    [\"ATTILAHILDMANN CHAT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Xavier Naidoo (public_channel)\n",
    "plotWordCloud(\n",
    "    \"DS-08-10-2020/ChatExport_2020-09-25-xavier\",\n",
    "    \"pc-xavier\",\n",
    "    [\"xavier_naidoo\", \"Xavier_Naidoo\", \"politische_bildersprueche\", \"einmal_hin_alles_drin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for test purposes\n",
    "plotWordCloud(\n",
    "    \"global\",\n",
    "    \"global\",\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_weighted = nx.DiGraph()\n",
    "\n",
    "#G_weighted.add_edge('A', 'B', weight=8)\n",
    "#G_weighted.add_edge('A', 'C', weight=2)\n",
    "#G_weighted.add_edge('A', 'D', weight=5)\n",
    "#G_weighted.add_edge('C', 'D', weight=3)\n",
    "#G_weighted.add_edge('A', 'C', weight=2)\n",
    "#G_weighted.add_edge('D', 'C', weight=10)\n",
    "#G_weighted.add_edge('C', 'E', weight=5)\n",
    "\n",
    "#G_weighted.add_node('A', weight=500)\n",
    "#G_weighted.add_node('C', weight=300)\n",
    "#G_weighted.add_node('D', weight=500)\n",
    "#G_weighted.add_node('B', weight=600)\n",
    "#G_weighted.add_node('E', weight=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipywidgets import interact\n",
    "#import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interact(plot_random_graph, n=(2,30), m=(1,10), k=(1,10), p=(0.0, 1.0, 0.001),\n",
    "#         generator={\n",
    "#             'lobster': random_lobster,\n",
    "#             'power law': powerlaw_cluster,\n",
    "#             'Newman-Watts-Strogatz': newman_watts_strogatz,\n",
    "#             u'Erdős-Rényi': erdos_renyi,\n",
    "#         });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
